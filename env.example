# Environment Variables for AgenticTableTop
# Copy this file to .env and fill in your API keys
# Never commit .env to git!

# LLM API Keys (at least one required)
OPENAI_API_KEY=sk-proj-your-key-here
GEMINI_API_KEY=AIza-your-key-here

# Pinecone Configuration (for vector storage)
PINECONE_API_KEY=pcsk_5BtcJG_9GRzrFMpwCKBYie2mhxWD8ungVjEFgvC8Beir9853d4Gf2J7cgJpuaUTszv8B88
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=agentictabletop-campaigns

# LLM Response Caching (for local development)
# Set to "false" to disable caching and always make fresh API calls
LLM_CACHE_ENABLED=true

# Cache expiry time in hours (default: 24 hours)
# Set to 0 to disable expiry (cache forever until manually cleared)
LLM_CACHE_EXPIRY_HOURS=24

# Database Configuration
# SQLite for development (default), PostgreSQL for production
DATABASE_URL=sqlite:///./agentictabletop.db
# For PostgreSQL: DATABASE_URL=postgresql://user:password@localhost/agentictabletop

# JWT Authentication
# Generate a secure random key for production: openssl rand -hex 32
JWT_SECRET_KEY=your-secret-key-change-in-production-use-openssl-rand-hex-32

# Configuration Notes:
# - You only need ONE of the above API keys (depending on which LLM you want to use)
# - Configure the model type in utils/model.py (MODEL_TYPE = "OPENAI" or "GEMINI")
# - Keep your API keys secret and never share them
# - LLM caching reduces API calls during development - disable for production

